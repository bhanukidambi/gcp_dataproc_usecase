# gcp_dataproc_usecase
Creating this repo to run pyspark jobs on Google DataProc cluster and automate it using Airflow DAGs. The data we use in this demo is a sample automobile data generated from Kaggle and modified it to make the sample size larger. It has duplicates and the PySpark job we run is basically dropping duplicates and saving the data.
